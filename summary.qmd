---
title: "Summary"
author: "Jake Glueckert"
date: "`r Sys.Date()`"
format: 
  html:
    code-fold: true
editor: source
toc: true
toc-depth: 4
toc-expand: true
folding: true
execute: 
  warning: false
editor_options: 
  chunk_output_type: console
---

# Intro

This is a data science project I started to convince myself to stop stressing on my commute to work. I asked myself the question, "How much time am I really saving when I rush on my drive to work? What is it costing me to drive faster?" I drive a 2016 prius, it can't really cost that much to save a bit of time, right? From those initial questions the project grew with more questions, and eventually  to be more of practicing data analysis skills and since I had a unique data set that I was intimately familiar with a fun way to learn new skills. This project has turned into a personal data analysis skills portfolio, as I work in a field where many people have open publications, while I have been at commercial firms my entire career and have no demonstration of my skills that I can openly share.  

# The Data

All data was collected by me, and logged into a google drive spreadsheet at the completion of each commute. Anyone interested has my blessing to use the data for practice and learning.

As happens with any data analysis, I realized as time went on that the next set of questions that came to mind required more data. I began collecting additional parameters as I thought of them to answer more fun questions, and to explain some large events that had a significant impact on the results. These included getting new tires and a bridge along my daily commute (The Washington bridge in Providence, RI) closing. Luckily I was able to WFH in the first couple weeks of the closure, so luckily/sadly don't have data from that period. 

## The rules

1. Follow the rules of the road (with the exception of the speed limit, which is arguable since not interrupting the flow of traffic is a law and safety concern - there's a weird phenomenon where people from the east coast physically cannot see speed limit signs. I've seen cops blending in with traffic going ~30 MPH over the speed limit and not do anything)

1. Preserve my sanity by driving however is easiest and least stressful

1. Don't be a dick and significantly inconvenience other people

1. Use cruise control as much as possible to stay at the stated speed

While driving on my 39 mile commute on the east coast, I aimed to use cruise control as much as possible to simplify my drive. I drive in the middle lane if it's 3 lanes, or the right lane if it's a 2 lane highway. I don't have adaptive cruise control, so if I came up to someone going slower than me I would pass them. Occasionally people would be passing me at the same time, so I would slow down until they passed, then resume my speed and pass. Occasionally I would have someone come up behind me as I was already passing, so I would speed up to pass faster so they could get by and then I would slow back down. 

These rules obviously lead to a fair bit of inherent variability. The goal of this started as stress reduction, so I stuck to those rules and accepted a bit of extra variability in my models to maintain my sanity. 

## Raw Data

I will intermittently upload the data to this github, but my daily tracker can be accessed [here](https://docs.google.com/spreadsheets/d/1HjWsuAeAIw3vRhwvQOpY1h-PCmE32JqtX_tgvplsVDQ/edit?usp=sharing)

I've added the data manipulations for later parts of the data collection and analysis to this initial data loading and wrangling section for convenience and simpification, this document is intended to read as a logical sequence rather than a chronological reasoning. 

I've set an arbitrary cost for gas for $/gallon based on my time on the east coast. Might change, might be updated, but for now is a largely irrelevant part of the analysis. 

```{r loading data, results='hide'}
#| include: false

require(googledrive)
require(viridis)
require(ggResidpanel)
require(plotly)
require(tidyverse)

cost <- 3.40
distance <- 39

drive_download("MPG", overwrite = TRUE,
               type = "csv")
2

mpg <- read_csv("MPG.csv",
                name_repair = "universal") |> 
  mutate(time_if_max_speed = distance / mph * 60,
         effective_mph = distance / (time / 60)) |> 
  mutate(gals_used = distance / mpg,
         cost = gals_used * cost,
         traffic = time - time_if_max_speed,
         `effective mph` = as.numeric(effective_mph)) |> 
  filter(!is.na(mpg))
mpg$tires <- mpg$tires |> 
  replace_na("new")
mpg$traffic_pattern <- mpg$traffic_pattern |>
  replace_na(2) 
mpg$year <- mpg$year |>
  replace_na(2024)

mpg <- mpg |> 
  mutate(traffic_pattern = as.character(traffic_pattern))

mpg$date  <- mpg |> 
  mutate(date_full = paste0(date,year)) |> 
  pull(date_full) |> 
  as.Date("%d%b%Y") 
```


# Exploratory Data Analysis

Here's was the first check for what the data looked like, since the first obvious question is what is the effect on my mileage given my speed?

```{r mph_vs_mpg}

ggplotly(
  mpg |> 
    ggplot(aes(mph,
               mpg))+
    geom_point() +
    geom_smooth(method = "lm",)+
    labs(title = "Cruise Control Setting") ,
  dynamicTicks = T
)
```

I had already started tracking when I got new tires, and immediately noticed the drop in mileage. Here's what it looks like when I break it out by old vs new tires. 

```{r mph_vs_mpg_facet}
ggplotly(
  mpg |> 
    ggplot(aes(mph,
               mpg))+
    geom_point() +
    geom_smooth(method = "lm",)+
    facet_wrap(facets = "tires")+
    labs(title = "Cruise Control Setting") ,
  dynamicTicks = T
)
```

And another way to look at it:

```{r mph_vs_mpg_color}
ggplotly(
  mpg |> 
    ggplot(aes(mph,
               mpg,
               color = tires))+
    geom_point() +
    geom_smooth(method = "lm",)+
    labs(title = "Cruise Control Setting") ,
  dynamicTicks = T
)
```

In case anyone is not familiar with how tires work and what the results look like, I basically had racing slicks with almost no tread. [Rolling resistance](https://en.wikipedia.org/wiki/Rolling_resistance) is a real thing folks. 

```{r mph_vs_mpg_vsdate}
ggplotly(
  mpg |> 
    ggplot(aes(mph,
               mpg,
               color = date)) + 
    geom_point() +
    scale_color_viridis() ,
  dynamicTicks = T
)
```


Hmmm, the old vs new tires have a clear separation, but my gut feels like there's still a seasonality effect that I'm not correcting for....

Let's re-arrange the variables a bit.

```{r}
mpg |> 
  
ggplotly(
  mpg |> 
    ggplot(aes(date,
               mpg,
               color = mph)) + 
    geom_point() +
    geom_vline(xintercept = (as.Date("2023-05-28"))) +
    scale_color_viridis()  ,
  dynamicTicks = T
)

```

Seems like there's a pretty nice clean drop off at the time I changed to new tires, but still a decline after November. It's interesting because while there's a decrease in temperatures around where I live starting around ~November that would account for a drop in mileage and efficiency, it's wasn't a large change from November to December. I'll get back to the seasonality and maybe some time series analysis later once I've got a bit more data

::: {.callout-note title="TODO"}
Pull historical weather data and add temperature as a variable in the analysis.
:::

```{r}
ggplotly(
  mpg |> 
    ggplot(aes(date,
               mpg,
               color = mph)) + 
    geom_point() +
    geom_vline(xintercept = (as.Date("2023-05-28"))) +
    geom_vline(xintercept = (as.Date("2023-11-01"))) +
    geom_vline(xintercept = (as.Date("2023-12-13"))) +
    geom_vline(xintercept = (as.Date("2024-2-05"))) +
    scale_color_viridis() ,
  dynamicTicks = T
)
```

 Sadly for my mental health, there's an obvious answer.... [the Washignton Bridge closure ](https://en.wikipedia.org/wiki/Washington_Bridge_(Providence,_Rhode_Island)#2023_westbound_closure). There was an additional shift in the traffic patterns at the start of February, 


# The Main Question

Is it worth it to drive faster on my commute? I'll answer this question by breaking it down into a couple components: 

1. How much time do I actually save by driving faster? 

1. How much does it cost me to drive faster? 

I didn't log or quantify it, but generally going faster that 70 mph I have to pass people and disable cruise control which is more stressful. The dream is a stress-free commute which is why the majority of my data is below 70 mph. 


```{r}
mpg |> 
  ggplot(aes(mph)) + 
  stat_ecdf() + 
  scale_x_continuous(minor_breaks = seq(60,90,by=1))
```

I typically prefer an empirical cumulative distribution function (ECDF) plot over a histogram to avoid the hassle of figuring out the proper bins. An ECDF plot shows you the distribution of the data, with no chance for accidentally setting the wrong number of bins and mistinterpreting the data. There's no summarization, just raw data <3. 

## How much time do I save?

There's several factors that go into the time it takes to commute. The only real factor I can control is how fast I drive. Some other factors are traffic, time of day, day of the week, and more. I'll leave all of those out of the analysis for now.

::: {.callout-note title="TODO"}
Maybe in the future I'll spend the time to add in the weekday to the analysis and quantify the impact. Maybe I'll even get crazy and check if there was precipitation during the day when I would be commuting and see how much more/less traffic there is and how much slower it goes during bad weather... 
:::


```{r }

ggplotly(
  mpg |> 
    ggplot(aes(date,
               time,
               color = mph)) + 
    geom_point() +
    scale_color_viridis() +
    labs(title = "Cruise Control Setting") ,
  dynamicTicks = T
)
```




```{r }

ggplotly(
  mpg |> 
    ggplot(aes(mph,
               time,
               color = date)) + 
    geom_point() +
    geom_smooth(method = "lm",) +
    scale_color_viridis() +
    labs(title = "Cruise Control Setting") ,
  dynamicTicks = T
)
```



```{r}
fit <- mpg |> 
  lm(time ~ mph * commute * traffic_pattern,
     data = _)

prediction_data <- tibble(mph = seq(min(mpg$mph), max(mpg$mph)),)

```


### Bonus Question! 

RIDOT posted [this](https://www.dot.ri.gov/projects/WashingtonBridgeClosure/docs/travel/001.%20I-195W%20from%20State%20Line%20to%20I-95%20split.pdf) with the estimated difference in commuting times. It doesn't seem too accurate based on just gut intuition, I've typically been commuting around 8-9 in the morning, and somewhere around 2-6 in the evening. Lets see if I can figure out what time they think I commute...



## How much does it cost me to drive faster?










# Random Analyses that I haven't written up yet

::: {.callout-note title="TODO"}
Clean up this and move it to a proper section
:::

```{r lm_fits}

# TODO add lm model for mpg vs mpg
# plot resid vs date to check for seasonality

# 
# mpg |> 
#   filter(tires == "new") |> 
#   ggplot(aes(date)
```

```{r traffic pattern}

mpg |> 
  ggplot(aes(mph,
             time,
             color = traffic_pattern))+
  geom_point()

bridge_impact <- mpg |> 
  lm(time ~ mph + traffic_pattern,
     data = _)

anova(bridge_impact)
summary(bridge_impact)

```


```{r google time}

mpg |> 
  mutate(mph = as.factor(mph)) |> 
  ggplot(aes(mph,
             time - Google.estimate )) + 
  geom_boxplot()

```